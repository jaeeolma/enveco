{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp model.alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729062494/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Callable, Any, Optional, Tuple, List\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet -style CNN for voxel data\n",
    "\n",
    "> Process 40x40x105 voxels with traditional CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@delegates(Learner.__init__)\n",
    "def alexnetvoxel_learner(dls, loss_func=None, y_range=None, config=None, n_out=None, n_in=3, **kwargs):\n",
    "    \n",
    "    if config is None: config = {}\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    model = AlexNetVoxel(n_in=n_in, num_classes=n_out)\n",
    "    apply_init(model, nn.init.kaiming_normal_)\n",
    "    learn = Learner(dls, model, loss_func=loss_func, **kwargs)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building blocks and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "    \n",
    "def calc_same_padding_2d(inshape:tuple, kernel:tuple, strides:tuple) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Calculate layer sizes similarly to tensorflow padding='same' for 2d data.\n",
    "    [left, right, top, bot] is the order for F.pad.\n",
    "    Has some kind of performance penalty.\n",
    "    \"\"\"\n",
    "    _, _, in_h, in_w = inshape\n",
    "    krl_h, krl_w = kernel\n",
    "    str_h, str_w = strides\n",
    "    \n",
    "    out_h = np.ceil(float(in_h) / float(str_h))\n",
    "    out_w = np.ceil(float(in_w) / float(str_w))\n",
    "        \n",
    "    # width padding\n",
    "    if (in_w % str_w == 0):\n",
    "        pad_along_w = max(krl_w - str_w, 0)\n",
    "    else:\n",
    "        pad_along_w = max(krl_w - (in_w % str_w), 0)\n",
    "        \n",
    "    # height padding\n",
    "    if (in_h % str_h == 0):\n",
    "        pad_along_h = max(krl_h - str_h, 0)\n",
    "    else:\n",
    "        pad_along_h = max(krl_h - (in_h % str_h), 0)\n",
    "        \n",
    "    pad_left = pad_along_w // 2\n",
    "    pad_right = pad_along_w - pad_left\n",
    "    pad_top = pad_along_h // 2\n",
    "    pad_bot = pad_along_h - pad_top\n",
    "    return (pad_left, pad_right, pad_top, pad_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "        \n",
    "class PaddedConv2d(nn.Module):\n",
    "    \"Module for Conv3d-BN-relu, with the option for tensorflow-style `same` padding\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        bias:bool=False,\n",
    "        same_padding:bool=False,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super(PaddedConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=bias, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.same_padding = same_padding\n",
    "        self.kernel = kwargs['kernel_size']\n",
    "        self.stride = kwargs['stride']\n",
    "        self.padding_size = None\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.same_padding:\n",
    "            if self.padding_size == None:\n",
    "                self.padding_size = calc_same_padding_2d(x.shape, self.kernel, self.stride)\n",
    "            x = F.pad(x, self.padding_size)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "\n",
    "class PaddedMaxPool2d(nn.Module):\n",
    "    \"Module for MaxPool3d with optional tensorflow-style `same` padding\"\n",
    "    \n",
    "    def __init__(self, same_padding:bool=False, **kwargs: Any) -> None:\n",
    "        super(PaddedMaxPool2d, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(**kwargs)\n",
    "        self.same_padding = same_padding\n",
    "        self.kernel = kwargs['kernel_size']\n",
    "        self.stride = kwargs['stride']\n",
    "        self.padding_size = None\n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        if self.same_padding:\n",
    "            if self.padding_size == None:\n",
    "                self.padding_size = calc_same_padding_2d(x.shape, self.kernel, self.stride)\n",
    "            x = F.pad(x, self.padding_size)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexnetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class AlexNetVoxel(nn.Module):\n",
    "    \"Custom AlexNet for voxel data\"\n",
    "    \n",
    "    def __init__(self, n_in:int, num_classes:int=1) -> None:\n",
    "        super(AlexNetVoxel, self).__init__()\n",
    "        \n",
    "        self.conv1 = PaddedConv2d(n_in, 1050, kernel_size=(2,2), stride=(1,1), same_padding=True)\n",
    "        self.pool1 = PaddedMaxPool2d(kernel_size=(2,2), stride=(2,2), same_padding=False)\n",
    "        \n",
    "        self.conv2 = PaddedConv2d(1050, 256, kernel_size=(3,3), stride=(1,1), same_padding=True)\n",
    "        self.pool2 = PaddedMaxPool2d(kernel_size=(2,2), stride=(2,2), same_padding=False)\n",
    "        \n",
    "        self.conv3 = PaddedConv2d(256, 384, kernel_size=(3,3), stride=(1,1), same_padding=True)\n",
    "        self.conv4 = PaddedConv2d(384, 384, kernel_size=(3,3), stride=(1,1), same_padding=True)\n",
    "        self.pool4 = PaddedMaxPool2d(kernel_size=(2,2), stride=(2,2), same_padding=False)\n",
    "        \n",
    "        self.conv5 = PaddedConv2d(384, 256, kernel_size=(3,3), stride=(1,1), same_padding=True)\n",
    "        self.pool5 = PaddedMaxPool2d(kernel_size=(2,2), stride=(2,2), same_padding=False)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.dense1 = LinBnDrop(1024,4096)\n",
    "        self.dense2 = LinBnDrop(4096,4096)\n",
    "        self.dense3 = LinBnDrop(4096,1000)\n",
    "        self.output = LinBnDrop(1000,num_classes, bn=False)\n",
    "        \n",
    "    def forward(self, x:Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNetVoxel(n_in=105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 1050, 40, 40]         441,000\n",
      "       BatchNorm2d-2         [-1, 1050, 40, 40]           2,100\n",
      "      PaddedConv2d-3         [-1, 1050, 40, 40]               0\n",
      "         MaxPool2d-4         [-1, 1050, 20, 20]               0\n",
      "   PaddedMaxPool2d-5         [-1, 1050, 20, 20]               0\n",
      "            Conv2d-6          [-1, 256, 20, 20]       2,419,200\n",
      "       BatchNorm2d-7          [-1, 256, 20, 20]             512\n",
      "      PaddedConv2d-8          [-1, 256, 20, 20]               0\n",
      "         MaxPool2d-9          [-1, 256, 10, 10]               0\n",
      "  PaddedMaxPool2d-10          [-1, 256, 10, 10]               0\n",
      "           Conv2d-11          [-1, 384, 10, 10]         884,736\n",
      "      BatchNorm2d-12          [-1, 384, 10, 10]             768\n",
      "     PaddedConv2d-13          [-1, 384, 10, 10]               0\n",
      "           Conv2d-14          [-1, 384, 10, 10]       1,327,104\n",
      "      BatchNorm2d-15          [-1, 384, 10, 10]             768\n",
      "     PaddedConv2d-16          [-1, 384, 10, 10]               0\n",
      "        MaxPool2d-17            [-1, 384, 5, 5]               0\n",
      "  PaddedMaxPool2d-18            [-1, 384, 5, 5]               0\n",
      "           Conv2d-19            [-1, 256, 5, 5]         884,736\n",
      "      BatchNorm2d-20            [-1, 256, 5, 5]             512\n",
      "     PaddedConv2d-21            [-1, 256, 5, 5]               0\n",
      "        MaxPool2d-22            [-1, 256, 2, 2]               0\n",
      "  PaddedMaxPool2d-23            [-1, 256, 2, 2]               0\n",
      "          Flatten-24                 [-1, 1024]               0\n",
      "      BatchNorm1d-25                 [-1, 1024]           2,048\n",
      "           Linear-26                 [-1, 4096]       4,194,304\n",
      "      BatchNorm1d-27                 [-1, 4096]           8,192\n",
      "           Linear-28                 [-1, 4096]      16,777,216\n",
      "      BatchNorm1d-29                 [-1, 4096]           8,192\n",
      "           Linear-30                 [-1, 1000]       4,096,000\n",
      "           Linear-31                    [-1, 1]           1,001\n",
      "================================================================\n",
      "Total params: 31,048,389\n",
      "Trainable params: 31,048,389\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.64\n",
      "Forward/backward pass size (MB): 49.81\n",
      "Params size (MB): 118.44\n",
      "Estimated Total Size (MB): 168.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (105,40,40), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.image.ipynb.\n",
      "Converted 01_data.las.ipynb.\n",
      "Converted 02_tabular.preprocessing.ipynb.\n",
      "Converted 03_model.inception3dv3.ipynb.\n",
      "Converted 04_interpretation.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_model.ensemble.ipynb.\n",
      "Converted 07_model.alexnet.ipynb.\n",
      "Converted index.ipynb.\n",
      "converting: /scratch/mayrajan/enveco/nbs/07_model.alexnet.ipynb\n",
      "converting /scratch/mayrajan/enveco/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!nbdev_build_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
