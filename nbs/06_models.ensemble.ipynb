{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models\n",
    "\n",
    "Classes for ensembling several `Learner`s into one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basics import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Ensemble():\n",
    "    def __init__(self, dls, n_models:int=10, learn_func=Learner, cv:bool=False, **learner_kwargs):\n",
    "        \"\"\"Create an ensemble of `Learner`s. learner_func defines what kind of learner is used.\n",
    "        If cv is true, split the training set into `n_models` folds and use \n",
    "        \"\"\"\n",
    "        \n",
    "        self.dls = dls\n",
    "        self.metrics = learner_kwargs['metrics']\n",
    "        self.models = []\n",
    "        for _ in range(n_models):\n",
    "            if cv: \n",
    "                fold_dls = self.dls # Work in progress\n",
    "                self.models.append(learn_func(dls=fold_dls, **learner_kwargs))\n",
    "            else: \n",
    "                self.models.append(learn_func(dls=self.dls, **learner_kwargs))\n",
    "        \n",
    "    def fit_one_cycle(self, n_iterations, max_lr, **kwargs):\n",
    "        \"Fit the models with fit_one_cycle\"\n",
    "        for m in self.models:\n",
    "            m.fit_one_cycle(n_iterations, max_lr=max_lr, **kwargs)\n",
    "    \n",
    "    \n",
    "    def validate(self, dl=None) -> pd.DataFrame:\n",
    "        \"Validate all models individually and as an ensemble\"\n",
    "        if dl is None: dl=self.dls[1]\n",
    "        model_results = torch.cat([m.get_preds(reorder=False, dl=dl)[0] for m in self.models], dim=-1)\n",
    "        ensemble_results = model_results.sum(axis=-1) / len(self.models)\n",
    "        res_df = pd.DataFrame(columns=['model_identifier'] + [m.name if hasattr(m, 'name') else m.__name__ for m in self.metrics])\n",
    "        res_df.loc[0] = (['ensemble'] \n",
    "                         + [metric(ensemble_results, Tensor(dl.items.y.values)).item() for metric in self.metrics])\n",
    "        for i in range(len(self.models)):\n",
    "            res_df.loc[i+1] = ([i] \n",
    "                               + [metric(model_results[:,i], Tensor(dl.items.y.values)).item()  for metric in self.metrics])\n",
    "        return res_df\n",
    "    \n",
    "    def get_ensemble_preds(self, ds_idx=1, dl=None, with_input=True, with_decoded=False, with_loss=False, act=None,\n",
    "                           inner=False, reorder=False, cbs=None, **kwargs):\n",
    "        \"get_preds but ensemble results\"\n",
    "        if dl is None: dl=self.dls[1].new(shuffled=False, drop_last=False)\n",
    "        if reorder and hasattr(dl, 'get_idxs'):\n",
    "            idxs = dl.get_idxs()\n",
    "            dl = dl.new(get_idxs = _ConstantFunc(idxs))\n",
    "        model_results = []\n",
    "        for m in self.models:\n",
    "            model_results.append(m.get_preds(dl=dl, with_input=with_input, with_decoded=with_decoded, with_loss=with_loss,\n",
    "                                             act=act, inner=inner, reorder=reorder, cbs=cbs, **kwargs))\n",
    "        \n",
    "        ensemble_results = []\n",
    "        # iterate through results, could work better:\n",
    "        obs_idx = 0\n",
    "        if with_input: \n",
    "            ensemble_results.append(model_results[0][obs_idx])\n",
    "            obs_idx += 1\n",
    "        ensemble_results.append(sum([res[obs_idx] for res in model_results])/len(self.models))\n",
    "        obs_idx += 1\n",
    "        ensemble_results.append(model_results[0][obs_idx])\n",
    "        obs_idx += 1\n",
    "        if with_decoded:\n",
    "            ensemble_results.append(model_results[0][obs_idx])\n",
    "            obs_idx += 1\n",
    "        if with_loss:\n",
    "            ensemble_results.append(sum([res[obs_idx] for res in model_results])/len(self.models))\n",
    "        return tuple(ensemble_results)\n",
    "    \n",
    "    def predict(self, item):\n",
    "        model_results = [m.predict(item) for m in self.models]\n",
    "        ensemble_results = sum([res[-1] for res in model_results])/len(self.models)\n",
    "        ensemble_dec_results = sum([res[-2] for res in model_results])/len(self.models)\n",
    "        return (model_results[0][0], ensemble_dec_results, ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Ensemble` of `Learners` with `n_models`. Works pretty much like a single `Learner`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
