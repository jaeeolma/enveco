{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble models\n",
    "\n",
    "Classes for ensembling several `Learner`s into one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.basics import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Ensemble():\n",
    "    def __init__(self, dls, n_models:int=10, learn_cls=Learner, **learner_kwargs):\n",
    "        \"Create an ensemble of `Learner`s. learner_func is \"\n",
    "        \n",
    "        self.dls = dls\n",
    "        self.metrics = learner_kwargs['metrics']\n",
    "        self.models = []\n",
    "        for _ in range(n_models):\n",
    "            self.models.append(learn_cls(dls=dls, **learner_kwargs))\n",
    "        \n",
    "    def fit_one_cycle(self, n_iterations, max_lr, **kwargs):\n",
    "        \"Fit the models with fit_one_cycle\"\n",
    "        for m in self.models:\n",
    "            m.fit_one_cycle(n_iterations, max_lr=max_lr, **kwargs)\n",
    "            \n",
    "    def validate(self, dl=None) -> pd.DataFrame:\n",
    "        \"Validate all models individually and as an ensemble\"\n",
    "        if dl is None: dl=self.dls[1]\n",
    "        model_results = torch.cat([m.get_preds(reorder=False, dl=dl)[0] for m in self.models], dim=-1)\n",
    "        ensemble_results = model_results.sum(axis=-1) / len(self.models)\n",
    "        res_df = pd.DataFrame(columns=['model_identifier'] + [m.name if hasattr(m, 'name') else m.__name__ for m in self.metrics])\n",
    "        res_df.loc[0] = (['ensemble'] \n",
    "                         + [metric(ensemble_results, Tensor(dl.y.values)).item() for metric in self.metrics])\n",
    "        for i in range(len(self.models)):\n",
    "            res_df.loc[i+1] = ([i] \n",
    "                               + [metric(model_results[:,i], Tensor(dl.y.values)).item()  for metric in self.metrics])\n",
    "        return res_df\n",
    "    \n",
    "    def get_ensemble_preds(self, ds_idx=1, dl=None, with_input=True, with_decoded=False, with_loss=False, act=None,\n",
    "                           inner=False, reorder=False, cbs=None, **kwargs):\n",
    "        \"get_preds but ensemble results\"\n",
    "        if dl is None: dl=self.dls[1].new(shuffled=False, drop_last=False)\n",
    "        if reorder and hasattr(dl, 'get_idxs'):\n",
    "            idxs = dl.get_idxs()\n",
    "            dl = dl.new(get_idxs = _ConstantFunc(idxs))\n",
    "        model_results = []\n",
    "        for m in self.models:\n",
    "            model_results.append(m.get_preds(dl=dl, with_input=with_input, with_decoded=with_decoded, with_loss=with_loss,\n",
    "                                             act=act, inner=inner, reorder=reorder, cbs=cbs, **kwargs))\n",
    "        \n",
    "        ensemble_results = []\n",
    "        # iterate through results, could work better:\n",
    "        obs_idx = 0\n",
    "        if with_input: \n",
    "            ensemble_results.append(model_results[0][obs_idx])\n",
    "            obs_idx += 1\n",
    "        ensemble_results.append(sum([res[obs_idx] for res in model_results])/len(self.models))\n",
    "        obs_idx += 1\n",
    "        ensemble_results.append(model_results[0][obs_idx])\n",
    "        obs_idx += 1\n",
    "        if with_decoded:\n",
    "            ensemble_results.append(model_results[0][obs_idx])\n",
    "            obs_idx += 1\n",
    "        if with_loss:\n",
    "            ensemble_results.append(sum([res[obs_idx] for res in model_results])/len(self.models))\n",
    "        return tuple(ensemble_results)\n",
    "    \n",
    "    def predict(self, item):\n",
    "        model_results = [m.predict(item) for m in self.models]\n",
    "        ensemble_results = sum([res[-1] for res in model_results])/len(self.models)\n",
    "        ensemble_dec_results = sum([res[-2] for res in model_results])/len(self.models)\n",
    "        return (model_results[0][0], ensemble_dec_results, ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Ensemble` of `Learners` with `n_models`. Works pretty much like a single `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "@delegates(Ensemble.__init__)\n",
    "def tabular_ensemble(dls, n_models:int=10, layers=None, emb_szs=None, config=None, n_out=None, y_range=None, **kwargs):\n",
    "    \"Function to create Ensemble containing `TabularLearner`s\"\n",
    "    if config is None: config=tabular_config()\n",
    "    if layers is None: layers = [200, 100]\n",
    "    to = dls.train_ds\n",
    "    emb_szs = get_emb_sz(dls.train_ds, {} if emb_szs is None else emb_szs)\n",
    "    if n_out is None: n_out = get_c(dls)\n",
    "    assert n_out, \"`n_out` is not defined and could not be inferred from data, set `dls.c` or pass `n_out`\"\n",
    "    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n",
    "    model = TabularModel(emb_szs, len(dls.cont_names), n_out, layers, y_range=y_range, **config)\n",
    "    return Ensemble(dls, n_models=n_models, learn_cls=TabularLearner, model=model, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
