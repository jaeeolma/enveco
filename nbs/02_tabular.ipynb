{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular model utilities for Enveco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.tabular.all import *\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.data import get_grid\n",
    "from enveco.las import *\n",
    "from enveco.image import *\n",
    "import matplotlib.patches as mpl_patches\n",
    "from typing import Tuple\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess csv-files of our field plot data into `TabularPandas` to feed into models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_lidar_feature(row, path, feature_func, min_h:float=1.5, mask_plot=True):\n",
    "    \"Function for LiDAR opening and processing steps\"\n",
    "    las_data = las_to_df(f'{path}/{row.sampleplotid}.las')\n",
    "    if mask_plot == True: las_data = mask_plot_from_lidar(las_data, row.x, row.y)\n",
    "    features = feature_func(las_data, min_h)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_image_procs(row, path, radius=31, mask_plot=True):\n",
    "    \"Function for tif opening and processing steps\"\n",
    "    image_data = open_geotiff(f'{path}/{row.sampleplotid}.tif')\n",
    "    if mask_plot == True: image_data = mask_plot_from_image(image_data, radius=radius)\n",
    "    metrics = calc_image_metrics(image_data)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class EnvecoPreprocessor():\n",
    "    \n",
    "    def __init__(self, train_path, valid_path, test_path, **kwargs):\n",
    "        self.train_df = pd.read_csv(train_path)\n",
    "        self.train_df = self.train_df.rename(columns = lambda x: re.sub('[\\.]+', '_', x))\n",
    "        self.valid_df = pd.read_csv(valid_path)\n",
    "        self.valid_df = self.valid_df.rename(columns = lambda x: re.sub('[\\.]+', '_', x))\n",
    "        self.test_df = pd.read_csv(test_path)\n",
    "        self.test_df = self.test_df.rename(columns = lambda x: re.sub('[\\.]+', '_', x))\n",
    "        self.train_df['is_valid'] = 0\n",
    "        self.valid_df['is_valid'] = 1\n",
    "        self.train_val_df = pd.concat((self.train_df, self.valid_df))\n",
    "        \n",
    "        \n",
    "    def preprocess_lidar(self, target_col, path, min_h:float=1.5, mask_plot:bool=True, height_features:bool=True,\n",
    "                         point_features:bool=True, intensity_features:bool=True, height_quantiles:bool=True,\n",
    "                         point_proportions:bool=True, canopy_densities:bool=True, normalize:bool=True,\n",
    "                         log_y:bool=False) -> Tuple[TabularPandas, TabularPandas]:\n",
    "        \"Preprocess data and return (train_val, test) -tuple. Optionally log-transform target column with np.log1p\"\n",
    "        trainval = self.train_val_df.copy()\n",
    "        test = self.test_df.copy()\n",
    "        feature_cols = []\n",
    "        if height_features:\n",
    "            print('Adding height based features')\n",
    "            trainval[height_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_height_features, \n",
    "                                                                                 min_h, mask_plot), \n",
    "                                                   axis=1, result_type='expand')\n",
    "            test[height_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_height_features, \n",
    "                                                                         min_h, mask_plot), \n",
    "                                           axis=1, result_type='expand')\n",
    "            feature_cols.extend(height_cols)\n",
    "\n",
    "        if point_features:\n",
    "            print('Adding point distribution based features')\n",
    "            trainval[point_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_point_features, \n",
    "                                                                                min_h, mask_plot), \n",
    "                                                   axis=1, result_type='expand')\n",
    "            test[point_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_point_features, \n",
    "                                                                                 min_h, mask_plot), \n",
    "                                           axis=1, result_type='expand')\n",
    "            feature_cols.extend(point_cols)\n",
    "            \n",
    "        if intensity_features:\n",
    "            print('Adding intensity based features')\n",
    "            trainval[intensity_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_intensity_features, \n",
    "                                                                                    min_h, mask_plot), \n",
    "                                                   axis=1, result_type='expand')\n",
    "            test[intensity_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_intensity_features, \n",
    "                                                                            min_h, mask_plot), \n",
    "                                              axis=1, result_type='expand')\n",
    "            feature_cols.extend(intensity_cols)\n",
    "            \n",
    "        if height_quantiles:\n",
    "            print('Adding height quantiles')\n",
    "            trainval[quantile_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_height_quantiles, \n",
    "                                                                                  min_h, mask_plot), \n",
    "                                                   axis=1, result_type='expand')\n",
    "            test[quantile_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_height_quantiles,\n",
    "                                                                           min_h, mask_plot), \n",
    "                                             axis=1, result_type='expand')\n",
    "            feature_cols.extend(quantile_cols)\n",
    "            \n",
    "        if point_proportions:\n",
    "            print('Adding point proportions')\n",
    "            trainval[proportion_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_point_proportions, \n",
    "                                                                                    min_h, mask_plot), \n",
    "                                                       axis=1, result_type='expand')\n",
    "            test[proportion_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_point_proportions, \n",
    "                                                                                 min_h, mask_plot), \n",
    "                                               axis=1, result_type='expand')\n",
    "            feature_cols.extend(proportion_cols)\n",
    "            \n",
    "        if canopy_densities:\n",
    "            print('Adding canopy densities')\n",
    "            trainval[density_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_canopy_densities, \n",
    "                                                                                    min_h, mask_plot), \n",
    "                                                       axis=1, result_type='expand')\n",
    "            test[density_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_canopy_densities, \n",
    "                                                                                 min_h, mask_plot), \n",
    "                                               axis=1, result_type='expand')\n",
    "            feature_cols.extend(density_cols)   \n",
    "        \n",
    "        if log_y:\n",
    "            trainval[target_col] = np.log1p(trainval[target_col])\n",
    "            test[target_col] = np.log1p(test[target_col])\n",
    "        \n",
    "        means = []\n",
    "        stds = []\n",
    "        #for c in feature_cols:\n",
    "        #    means.append(trainval[trainval.is_valid==0][c].mean())\n",
    "        #    stds.append(trainval[trainval.is_valid==0][c].std())\n",
    "        #norm_stats = np.array((means,stds))\n",
    "        procs = None\n",
    "        if normalize:\n",
    "            procs = [Normalize]#.from_stats(*norm_stats)]\n",
    "        trainval_tb = TabularPandas(trainval, procs=procs,\n",
    "                                    cont_names=feature_cols, y_names=target_col,\n",
    "                                    splits=ColSplitter(col='is_valid')(trainval))\n",
    "        test_tb = TabularPandas(test, procs=procs,\n",
    "                                cont_names=feature_cols, y_names=target_col)\n",
    "        return trainval_tb, test_tb\n",
    "    \n",
    "    def preprocess_image(self, target_col, path, radius:int=31, mask_plot=True) -> Tuple[TabularPandas, TabularPandas]:\n",
    "        \"Preprocess dataframes and return (train_val, test) -tuple\"\n",
    "        # TODO\n",
    "        pass\n",
    "    \n",
    "    def preprocess_lidar_and_image(self, target_col, path, min_h:float=1.5, radius:int=31, \n",
    "                                   mask_plot:bool=True) -> Tuple[TabularPandas, TabularPandas]:\n",
    "        \"Preprocess dataframes and return (train_val, test) -tuple\"\n",
    "        # TODO\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional metrics to evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def adjusted_R2Score(r2_score, n, k):\n",
    "    \"Calculates adjusted_R2Score based on r2_score, number of observations (n) and number of predictor variables(k)\"\n",
    "    return 1 - (((n-1)/(n-k-1)) * (1 - r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _rrmse(inp, targ):\n",
    "    \"RMSE normalized with mean of the target\"\n",
    "    return torch.sqrt(F.mse_loss(inp, targ)) / targ.mean() * 100\n",
    "    \n",
    "rrmse = AccumMetric(_rrmse)\n",
    "rrmse.__doc__ = \"Target mean weighted rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"rrmse\" class=\"doc_header\"><code>rrmse</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>rrmse</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Target mean weighted rmse"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(rrmse, name='rrmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias(inp, targ):\n",
    "    \"Bias metric\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return (inp - targ).sum() / len(targ)\n",
    "\n",
    "bias = AccumMetric(_bias)\n",
    "bias.__doc__ = 'Bias metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Bias metric\" class=\"doc_header\"><code>Bias metric</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Bias metric</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Bias metric"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bias, name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias_pct(inp, targ):\n",
    "    \"Percent bias\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return 100 * ((inp-targ).sum()/len(targ)) / targ.mean()\n",
    "\n",
    "bias_pct = AccumMetric(_bias_pct)\n",
    "bias_pct.__doc__ = 'Mean weighted bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Mean weighted bias\" class=\"doc_header\"><code>Mean weighted bias</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Mean weighted bias</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Mean weighted bias"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bias_pct, name='bias_pct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble of tabular learners with `n_models`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ANNEnsemble():\n",
    "    \n",
    "    def __init__(self, dls, metrics, y_range:tuple=None, n_models=10, **learner_kwargs):\n",
    "        \"Create an ensemble of ANN models. TODO add option to use different parameters or different split for dataset\"\n",
    "        self.dls = dls\n",
    "        self.metrics = metrics\n",
    "        self.models = []\n",
    "        for _ in range(n_models):\n",
    "            # This way instead of list comprehension because possible model-specific settings            \n",
    "            self.models.append(tabular_learner(dls, metrics=metrics, y_range=y_range, **learner_kwargs))\n",
    "        \n",
    "    def fit_one_cycle(self, n_iterations, max_lr):\n",
    "        \"Fit the models\"\n",
    "        for m in self.models:\n",
    "            m.fit_one_cycle(n_iterations, max_lr=max_lr)\n",
    "            \n",
    "    def validate(self, dl=None) -> pd.DataFrame:\n",
    "        \"Validate all models individually and as an ensemble\"\n",
    "        if dl is None: dl=self.dls[1]\n",
    "        model_results = torch.cat([m.get_preds(reorder=False, dl=dl)[0] for m in self.models], dim=-1)\n",
    "        ensemble_results = model_results.sum(axis=-1) / len(self.models)\n",
    "        res_df = pd.DataFrame(columns=['model_identifier'] + [m.name if hasattr(m, 'name') else m.__name__ for m in self.metrics])\n",
    "        res_df.loc[0] = (['ensemble'] \n",
    "                         + [metric(ensemble_results, Tensor(dl.y.values)).item() for metric in self.metrics])\n",
    "        for i in range(len(self.models)):\n",
    "            res_df.loc[i+1] = ([i] \n",
    "                               + [metric(model_results[:,i], Tensor(dl.y.values)).item()  for metric in self.metrics])\n",
    "        return res_df\n",
    "    \n",
    "    def get_ensemble_preds(self, ds_idx=1, dl=None, with_input=True, with_decoded=False, with_loss=False, act=None,\n",
    "                           inner=False, reorder=False, cbs=None, **kwargs):\n",
    "        \"get_preds but ensemble results\"\n",
    "        if dl is None: dl=self.dls[1].new(shuffled=False, drop_last=False)\n",
    "        if reorder and hasattr(dl, 'get_idxs'):\n",
    "            idxs = dl.get_idxs()\n",
    "            dl = dl.new(get_idxs = _ConstantFunc(idxs))\n",
    "        model_results = []\n",
    "        for m in self.models:\n",
    "            model_results.append(m.get_preds(dl=dl, with_input=with_input, with_decoded=with_decoded, with_loss=with_loss,\n",
    "                                             act=act, inner=inner, reorder=reorder, cbs=cbs, **kwargs))\n",
    "        \n",
    "        ensemble_results = []\n",
    "        # iterate through results:\n",
    "        obs_idx = 0\n",
    "        if with_input: \n",
    "            ensemble_results.append(model_results[0][obs_idx])\n",
    "            obs_idx += 1\n",
    "        ensemble_results.append(sum([res[obs_idx] for res in model_results])/len(self.models))\n",
    "        obs_idx += 1\n",
    "        ensemble_results.append(model_results[0][obs_idx])\n",
    "        obs_idx += 1\n",
    "        if with_decoded:\n",
    "            ensemble_results.append(model_results[0][obs_idx])\n",
    "            obs_idx += 1\n",
    "        if with_loss:\n",
    "            ensemble_results.append(sum([res[obs_idx] for res in model_results])/len(self.models))\n",
    "        return tuple(ensemble_results)\n",
    "    \n",
    "    def predict(self, item):\n",
    "        model_results = [m.predict(item) for m in self.models]\n",
    "        ensemble_results = sum([res[-1] for res in model_results])/len(self.models)\n",
    "        ensemble_dec_results = sum([res[-2] for res in model_results])/len(self.models)\n",
    "        return (model_results[0][0], ensemble_dec_results, ensemble_results)\n",
    "    \n",
    "    \n",
    "    def export(self, path, pickle_protocol=2):\n",
    "        \"Save each Learner in the ensemble\"\n",
    "        pass\n",
    "\n",
    "def load_ensemble(path, cpu=True) -> ANNEnsemble:\n",
    "    # Read config and dls\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend fastai Interpretation to work with regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class RegressionInterpretation(Interpretation):\n",
    "    \"Interpretation for regression models\"\n",
    "    \n",
    "    def __init__(self, dl, inputs, preds, targs, decoded, losses):\n",
    "        super().__init__(dl, inputs, preds, targs, decoded, losses)\n",
    "        \n",
    "    def plot_results(self, title='Regression results', log_y:bool=False, **kwargs) -> plt.Axes:\n",
    "        \"Plot nice result image for regression tasks, code still need prettifying\"\n",
    "        axs = get_grid(self.dl.c, figsize=((6+1)*self.dl.c, (6)*self.dl.c)) # if we have multitarget\n",
    "        if log_y: \n",
    "            self.targs = torch.expm1(self.targs)\n",
    "            self.preds = torch.expm1(self.preds)\n",
    "        if len(self.targs.shape) == 1: self.targs = self.targs[:,None]\n",
    "        for i, a in enumerate(axs):\n",
    "            im = a.scatter(self.targs[:,i], self.preds[:,i], c=torch.abs(self.targs[:,i]-self.preds[:,i]))\n",
    "            a.set_xlabel('Real value')\n",
    "            a.set_ylabel('Predicted value')\n",
    "            if hasattr(self.dl, 'y_names'):\n",
    "                a.set_title(self.dl.y_names[i])\n",
    "            else:\n",
    "                a.set_title('Results')\n",
    "            a.grid()\n",
    "            x = np.linspace(0, max(self.preds[:,i].max(),self.targs[:,i].max()))\n",
    "            a.plot(x, x, color='orange')\n",
    "            cbar = plt.colorbar(im, ax=a)\n",
    "            cbar.ax.set_ylabel('Deviations', rotation=90)\n",
    "            res_mae = mae(self.targs[:,i], self.preds[:,i])\n",
    "            res_mse = mse(self.targs[:,i], self.preds[:,i])\n",
    "            res_rmse = rmse(self.targs[:,i], self.preds[:,i]) \n",
    "            res_rrmse = res_rmse / self.targs.mean() * 100\n",
    "            r2 = R2Score()(self.preds[:,i], self.targs[:,i])\n",
    "            adjusted_r2 = adjusted_R2Score(r2, self.inputs[1].shape[0], self.inputs[1].shape[1])\n",
    "            res_bias = bias(self.targs[:,i], self.preds[:,i])\n",
    "            res_pct_bias = bias_pct(self.targs[:,i], self.preds[:,i])\n",
    "\n",
    "            handles = [mpl_patches.Rectangle((0, 0), 1, 1, fc=\"white\", ec=\"white\", \n",
    "                       lw=0, alpha=0)] * 8\n",
    "            labels = [f'MSE: {res_mse:.2f}', f'RMSE: {res_rmse:.2f}', f'RRMSE: {res_rrmse:.2f}%',\n",
    "                      f'MAE: {res_mae:.2f}', f'R2: {r2:.2f}', f'Adj. R2: {adjusted_r2:.2f}',\n",
    "                      f'BIAS: {res_bias:.2f}', f'BIAS-%: {res_pct_bias:.2f}%']\n",
    "            a.legend(handles, labels, loc='best', fancybox=True, handlelength=0, handletextpad=0)\n",
    "        if log_y: \n",
    "            self.targs = torch.log1p(self.targs)\n",
    "            self.preds = torch.log1p(self.preds)\n",
    "        return axs\n",
    "    \n",
    "    @classmethod\n",
    "    def from_ensemble(cls, ensemble, ds_idx=1, dl=None, act=None):\n",
    "        \"Construct interpretation object from an ensemble of learners\"\n",
    "        if dl is None: dl = ensemble.dls[ds_idx]\n",
    "        return cls(dl, *ensemble.get_ensemble_preds(dl=dl, with_input=True, with_loss=True, with_decoded=True, act=act))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get similar images than `RegressionInterpretation` with sklearn-models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def plot_sklearn_regression(model, X:TabularPandas, y:TabularPandas, log_y:bool=False, **kwargs) -> plt.Axes:\n",
    "    \"Similar plotting utility than RegressionInterpretation\"\n",
    "    preds = model.predict(X)\n",
    "    if len(preds.shape) != 2: preds = preds[:,None]\n",
    "    cols = y.columns\n",
    "    y = y.values\n",
    "    if log_y: \n",
    "        preds = np.expm1(preds)\n",
    "        y = np.expm1(y)\n",
    "    axs = get_grid(y.shape[1], figsize=((6+1)*y.shape[1], (6)*y.shape[1])) # if we have multitarget\n",
    "    for i, a in enumerate(axs):\n",
    "        im = a.scatter(y[:,i], preds[:,i], c=np.abs(y[:,i]-preds[:,i]))\n",
    "        a.set_xlabel('Real value')\n",
    "        a.set_ylabel('Predicted value')\n",
    "        a.set_title(cols[i])\n",
    "        a.grid()\n",
    "        x = np.linspace(0, max(preds[:,i].max(),y[:,i].max()))\n",
    "        a.plot(x, x, color='orange')\n",
    "        cbar = plt.colorbar(im, ax=a)\n",
    "        cbar.ax.set_ylabel('Deviations', rotation=90)\n",
    "        res_mae = mae(Tensor(y[:,i]), Tensor(preds[:,i]))\n",
    "        res_mse = mse(Tensor(y[:,i]), Tensor(preds[:,i]))\n",
    "        res_rmse = rmse(Tensor(y[:,i]), Tensor(preds[:,i]))\n",
    "        res_rrmse = res_rmse / y.mean() * 100\n",
    "        r2 = R2Score()(Tensor(y[:,i]), Tensor(preds[:,i]))\n",
    "        adjusted_r2 = adjusted_R2Score(r2, X.shape[0], X.shape[1])\n",
    "        res_bias = bias(Tensor(y[:,i]), Tensor(preds[:,i]))\n",
    "        res_pct_bias = bias_pct(Tensor(y[:,i]), Tensor(preds[:,i]))\n",
    "        handles = [mpl_patches.Rectangle((0, 0), 1, 1, fc=\"white\", ec=\"white\", \n",
    "                   lw=0, alpha=0)] * 8\n",
    "        labels = [f'MSE: {res_mse:.2f}', f'RMSE: {res_rmse:.2f}', f'RRMSE: {res_rrmse:.2f}%',\n",
    "                  f'MAE: {res_mae:.2f}', f'R2: {r2:.2f}', f'Adj. R2: {adjusted_r2:.2f}',\n",
    "                  f'BIAS: {res_bias:.2f}', f'BIAS-%: {res_pct_bias:.2f}%']\n",
    "        a.legend(handles, labels, loc='best', fancybox=True, handlelength=0, handletextpad=0)\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
