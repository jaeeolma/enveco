{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Additional regression metrics used for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import flatten_check\n",
    "from fastai.imports import *\n",
    "from fastai.losses import BaseLoss\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def adjusted_R2Score(r2_score, n, k):\n",
    "    \"Calculates adjusted_R2Score based on r2_score, number of observations (n) and number of predictor variables(k)\"\n",
    "    return 1 - (((n-1)/(n-k-1)) * (1 - r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2-score for R2-score of 0.8 with 300 observations and 20 predicting variables is 0.786\n"
     ]
    }
   ],
   "source": [
    "r2 = 0.8\n",
    "n = 300\n",
    "k = 20\n",
    "print(f'Adjusted R2-score for R2-score of {r2} with {n} observations and {k} predicting variables is {round(adjusted_R2Score(r2,n,k),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _rrmse(inp, targ):\n",
    "    \"RMSE normalized with mean of the target\"\n",
    "    return torch.sqrt(F.mse_loss(inp, targ)) / targ.mean() * 100\n",
    "    \n",
    "rrmse = AccumMetric(_rrmse)\n",
    "rrmse.__doc__ = \"Target mean weighted rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4128), tensor(80.5734))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((100,1))\n",
    "targ = torch.rand((100,1))\n",
    "\n",
    "torch.sqrt(F.mse_loss(inp, targ)), _rrmse(inp,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"rrmse\" class=\"doc_header\"><code>rrmse</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>rrmse</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Target mean weighted rmse"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(rrmse, name='rrmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias(inp, targ):\n",
    "    \"Average bias of predictions\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return (inp - targ).sum() / len(targ)\n",
    "\n",
    "bias = AccumMetric(_bias)\n",
    "bias.__doc__ = \"Average bias of predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bias\" class=\"doc_header\"><code>bias</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bias</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Average bias of predictions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bias, name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.0039)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bias(inp, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias_pct(inp, targ):\n",
    "    \"Mean weighted bias\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return 100 * ((inp-targ).sum()/len(targ)) / targ.mean()\n",
    "\n",
    "bias_pct = AccumMetric(_bias_pct)\n",
    "bias_pct.__doc__ = 'Mean weighted bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bias_pct\" class=\"doc_header\"><code>bias_pct</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bias_pct</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Mean weighted bias"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bias_pct, name='bias_pct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7581)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bias_pct(inp, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.image.ipynb.\n",
      "Converted 01_data.las.ipynb.\n",
      "Converted 02_tabular.preprocessing.ipynb.\n",
      "Converted 03_model.inception3dv3.ipynb.\n",
      "Converted 04_interpretation.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_model.ensemble.ipynb.\n",
      "Converted 07_model.alexnet.ipynb.\n",
      "Converted index.ipynb.\n",
      "converting: /scratch/mayrajan/enveco/nbs/00_data.image.ipynb\n",
      "converting: /scratch/mayrajan/enveco/nbs/index.ipynb\n",
      "converting: /scratch/mayrajan/enveco/nbs/06_model.ensemble.ipynb\n",
      "converting: /scratch/mayrajan/enveco/nbs/01_data.las.ipynb\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "converting: /scratch/mayrajan/enveco/nbs/04_interpretation.ipynb\n",
      "converting: /scratch/mayrajan/enveco/nbs/07_model.alexnet.ipynb\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "converting: /scratch/mayrajan/enveco/nbs/02_tabular.preprocessing.ipynb\n",
      "converting: /scratch/mayrajan/enveco/nbs/05_metrics.ipynb\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "'HTMLExporter' object has no attribute 'template_path'\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/nbdev_build_docs\", line 10, in <module>\n",
      "    sys.exit(nbdev_build_docs())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/fastscript/core.py\", line 76, in _f\n",
      "    func(**args.__dict__)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/nbdev/cli.py\", line 221, in nbdev_build_docs\n",
      "    notebook2html(fname=fname, force_all=force_all, n_workers=n_workers, pause=pause)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/nbdev/export2html.py\", line 582, in notebook2html\n",
      "    raise Exception(msg + '\\n'.join([f.name for p,f in zip(passed,files) if not p]))\n",
      "Exception: Conversion failed on the following:\n",
      "06_model.ensemble.ipynb\n",
      "00_data.image.ipynb\n",
      "index.ipynb\n",
      "01_data.las.ipynb\n",
      "04_interpretation.ipynb\n",
      "07_model.alexnet.ipynb\n",
      "02_tabular.preprocessing.ipynb\n",
      "05_metrics.ipynb\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!nbdev_build_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
