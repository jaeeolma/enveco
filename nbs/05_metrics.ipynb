{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Additional regression metrics used for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import flatten_check\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def adjusted_R2Score(r2_score, n, k):\n",
    "    \"Calculates adjusted_R2Score based on r2_score, number of observations (n) and number of predictor variables(k)\"\n",
    "    return 1 - (((n-1)/(n-k-1)) * (1 - r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2-score for R2-score of 0.8 with 300 observations and 20 predicting variables is 0.786\n"
     ]
    }
   ],
   "source": [
    "r2 = 0.8\n",
    "n = 300\n",
    "k = 20\n",
    "print(f'Adjusted R2-score for R2-score of {r2} with {n} observations and {k} predicting variables is {round(adjusted_R2Score(r2,n,k),3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _rrmse(inp, targ):\n",
    "    \"RMSE normalized with mean of the target\"\n",
    "    return torch.sqrt(F.mse_loss(inp, targ)) / targ.mean() * 100\n",
    "    \n",
    "rrmse = AccumMetric(_rrmse)\n",
    "rrmse.__doc__ = \"Target mean weighted rmse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4326), tensor(87.6552))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.rand((100,1))\n",
    "targ = torch.rand((100,1))\n",
    "\n",
    "torch.sqrt(F.mse_loss(inp, targ)), _rrmse(inp,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"rrmse\" class=\"doc_header\"><code>rrmse</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>rrmse</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Target mean weighted rmse"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(rrmse, name='rrmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias(inp, targ):\n",
    "    \"Average bias of predictions\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return (inp - targ).sum() / len(targ)\n",
    "\n",
    "bias = AccumMetric(_bias)\n",
    "bias.__doc__ = \"Average bias of predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0405)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bias(inp, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bias\" class=\"doc_header\"><code>bias</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bias</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Average bias of predictions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bias, name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _bias_pct(inp, targ):\n",
    "    \"Mean weighted bias\"\n",
    "    inp, targ = flatten_check(inp, targ)\n",
    "    return 100 * ((inp-targ).sum()/len(targ)) / targ.mean()\n",
    "\n",
    "bias_pct = AccumMetric(_bias_pct)\n",
    "bias_pct.__doc__ = 'Mean weighted bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"bias_pct\" class=\"doc_header\"><code>bias_pct</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>bias_pct</code>(**`preds`**, **`targs`**)\n",
       "\n",
       "Mean weighted bias"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(bias_pct, name='bias_pct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.2101)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bias_pct(inp, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_data.image.ipynb.\n",
      "Converted 01_data.las.ipynb.\n",
      "Converted 02_tabular.preprocessing.ipynb.\n",
      "Converted 03_models.inception3dv3.ipynb.\n",
      "Converted 04_interpretation.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_models.ensemble.ipynb.\n",
      "Converted index.ipynb.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/bin/nbdev_build_docs\", line 8, in <module>\n",
      "    sys.exit(nbdev_build_docs())\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/site-packages/fastcore/script.py\", line 88, in _f\n",
      "    tfunc(**merge(args, args_from_prog(func, xtra)))\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/site-packages/nbdev/export2html.py\", line 659, in nbdev_build_docs\n",
      "    notebook2html(fname=fname, force_all=force_all, n_workers=n_workers, pause=pause)\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/site-packages/nbdev/export2html.py\", line 534, in notebook2html\n",
      "    files = [f for f in Config().path(\"nbs_path\").glob('**/*.ipynb')\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/site-packages/fastcore/foundation.py\", line 456, in __init__\n",
      "    self.d = read_config_file(self.config_file)['DEFAULT']\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/site-packages/fastcore/foundation.py\", line 437, in read_config_file\n",
      "    config.read(file)\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/configparser.py\", line 697, in read\n",
      "    self._read(fp, filename)\n",
      "  File \"/home/mayrajeo/miniconda3/envs/enveco/lib/python3.8/configparser.py\", line 1093, in _read\n",
      "    raise DuplicateOptionError(sectname, optname,\n",
      "configparser.DuplicateOptionError: While reading from Path('/mnt/d/Users/E1005164/enveco/settings.ini') [line 68]: option 'custom_sidebar' in section 'DEFAULT' already exists\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()\n",
    "!nbdev_build_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
