# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_data.image.ipynb (unless otherwise specified).

__all__ = ['open_geotiff', 'calc_normalized_spectral_index', 'calc_avi', 'calc_savi', 'calc_gci',
           'mask_plot_from_image', 'image_metrics', 'glcm_xplusy', 'glcm_xminusy', 'textural_features',
           'process_image_features']

# Cell
import rasterio as rio
import numpy as np
import matplotlib.pyplot as plt
from typing import List
import pandas as pd
import skimage
from skimage.feature import greycomatrix, greycoprops
from itertools import product

# Cell
def open_geotiff(fn, bands:List[int]=None) -> np.ndarray:
    """Open geotiff image from path, cast it to float and scale it to 0-1 range, optionally with only `bands` input bands."
    Returns numpy array of shape (C,W,H)
    """
    with rio.open(str(fn)) as f:
        data = f.read()
        data = data.astype(np.float32)
        data /= 255.
    if bands is not None: data = data[bands]
    return data

# Cell
def calc_normalized_spectral_index(im:np.ndarray, band_1:int, band_2:int) -> np.ndarray:
    "Calculate normalized spectral index (band_1 - band_2)/(band_1 + band_2). Can be used with NDVI and such simple indices"
    return (im[band_1] - im[band_2]) / (im[band_1] + im[band_2])

def calc_avi(im:np.ndarray, nir:int, red:int) -> np.ndarray:
    "Calculate AVI (nir *(1-red) * (nir-red))"
    return im[nir] * (1 - im[red]) * (nir - red)

def calc_savi(im:np.ndarray, nir:int, red:int, l:float=0.5) -> np.ndarray:
    "Calculate Soil Adjusted Vegetation Index ((nir-red)/(nir+red+l)) * (1+l). Default uses Landsat coefficient L"
    return ((im[nir] - im[red]) / (im[nir] + im[red] + l)) * (1 + l)

def calc_gci(im:np.ndarray, nir:int, green:int) -> np.ndarray:
    "Calculate Green Clorophyll Index nir/green - 1"
    return im[nir] / im[green] - 1

# Cell

def mask_plot_from_image(data:np.ndarray, radius:float=31) -> np.ndarray:
    "Select only data from within field plot of radius (radius-1) pixels"
    center = (int(data.shape[1]/2), int(data.shape[2]/2))
    Y, X = np.ogrid[:data.shape[1], :data.shape[2]]
    dist_from_center = np.sqrt((X-center[0])**2 + (Y-center[1])**2)
    mask = dist_from_center <= radius
    data[:,~mask] = np.nan
    return data



# Cell

def image_metrics(fn, mask_plot:bool=True, radius:int=31) -> dict:
    "Calculate metrics from NIR-red-green -images"
    image = open_geotiff(fn)
    if mask_plot == True: image = mask_plot_from_image(image, radius=radius)
    # Max, mean, std and coefficient of variation
    features = {}
    features['nir_max'] = np.nanmax(image[0])
    features['nir_min'] = np.nanmin(image[0])
    features['nir_mean'] = np.nanmean(image[0])
    features['nir_std'] = np.nanstd(image[0])
    features['nir_var'] = np.nanvar(image[0])

    features['red_max'] = np.nanmax(image[1])
    features['red_min'] = np.nanmin(image[1])
    features['red_mean'] = np.nanmean(image[1])
    features['red_std'] = np.nanstd(image[1])
    features['red_var'] = np.nanvar(image[1])

    features['green_max'] = np.nanmax(image[2])
    features['green_min'] = np.nanmin(image[2])
    features['green_mean'] = np.nanmean(image[2])
    features['green_std'] = np.nanstd(image[2])
    features['green_var'] = np.nanvar(image[2])

    # spectral indices
    # NDVI
    ndvi = calc_normalized_spectral_index(image, 0, 1)
    features['ndvi_max'] = np.nanmax(ndvi)
    features['ndvi_min'] = np.nanmin(ndvi)
    features['ndvi_mean'] = np.nanmean(ndvi)
    features['ndvi_std'] = np.nanstd(ndvi)
    features['ndvi_var'] = np.nanvar(ndvi)

    return features

# Cell

def glcm_xplusy(glcm, k, distance, angle):
    "sum each element where the indices of the glcm sum to k"
    s = 0
    for c in range(0, glcm.shape[0]):
        targ = k - c
        if targ >= 0 and targ < glcm.shape[0]: s += glcm[targ, c, distance, angle]
        if targ > k: return s
    return s

def glcm_xminusy(glcm, k, distance, angle):
    "sum each element where the difference of the indices is k"
    s = 0
    for c in range(0, glcm.shape[0]):
        targ = k + c
        if targ < glcm.shape[0]: s += glcm[targ, c, distance, angle]
    if k == 0: return s
    return s*2

def textural_features(fn,
                      band_names:List=['nir', 'red', 'green'],
                      distances:List[int]=[8],
                      angles:List[float]=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                      n_grey:int=20) -> dict:
    """Get textural features from images. Works close to R package radiomics `GLCMFeatures` functions.
    However skimage makes glcm a bit differently"""
    tex_features = {}
    im = open_geotiff(fn)
    for b in range(im.shape[0]):
        pref = band_names[b]

        # bin image to at maximum n_grey levels
        bins = np.linspace(im[b].min(),im[b].max(), min(n_grey, len(np.unique(im[b]))) + 1)
        binned_im = np.digitize(im[b], bins) - 1

        n_levels = binned_im.max() + 1
        # get glcm. Note that skimage makes glcm differently than radiomics
        glcm = greycomatrix(binned_im,
                            distances=distances,
                            angles=angles,
                            levels=n_levels,
                            normed=True, symmetric=True)

        # greycoprops gives some features easily
        # Others not so much
        means = np.zeros((len(distances), len(angles)))
        variances = np.zeros((len(distances), len(angles)))
        autocorrelations = np.zeros((len(distances), len(angles)))
        cluster_prominences = np.zeros((len(distances), len(angles)))
        cluster_shades = np.zeros((len(distances), len(angles)))
        cluster_tendencies = np.zeros((len(distances), len(angles)))
        diff_entropies = np.zeros((len(distances), len(angles)))
        energies = np.zeros((len(distances), len(angles)))
        entropies = np.zeros((len(distances), len(angles)))
        hgn1s = np.zeros((len(distances), len(angles)))
        idmns = np.zeros((len(distances), len(angles)))
        idns = np.zeros((len(distances), len(angles)))
        inverse_variances = np.zeros((len(distances), len(angles)))
        sum_averages = np.zeros((len(distances), len(angles)))
        sum_entropies = np.zeros((len(distances), len(angles)))
        sum_variances = np.zeros((len(distances), len(angles)))

        # Todo chech that multiple distances work
        for d,a in product(range(len(distances)), range(len(angles))):
            # means
            means[d,a] = np.sum(np.sum(glcm[:,:,d,a], axis=1) * np.arange(1,n_levels+1))

            scale_matrix = np.empty((n_levels, n_levels))

            for i, j in product(range(n_levels), range(n_levels)):
                # variance
                variances[d,a] += (((i) - means[d,a])**2) * glcm[i,j,d,a]

                # cluster metrix
                cluster_prominences[d,a] += ((i + j - 2*means[d,a])**4) * glcm[i,j,d,a]
                cluster_shades[d,a] += ((i+j - 2*means[d,a])**3)*glcm[i,j,0,a]
                cluster_tendencies[d,a] += ((i + j - 2 * means[d,a])**2) * glcm[i,j,d,a]

                # scale matrix for autocorrelations
                scale_matrix[i,j] = (i+1) * (j+1)

                # homogeneity 1
                hgn1s[d,a] += glcm[i,j,d,a] / (1 + (np.abs(i-j)))

                # IDM normalized
                idmns[d,a] += glcm[i,j,d,a] / (1 + ((np.abs(i-j)**2)/(n_levels)**2))

                # ID normalized
                idns[d,a] += glcm[i,j,d,a] / (1 + (np.abs(i-j)/n_levels))

                # Inverse variance
                if i != j: inverse_variances[d,a] += glcm[i,j,d,a] / np.abs(i-j)**2

            # autocorrelations
            autocorrelations[d,a] = np.sum(glcm[:,:,0,a]*scale_matrix)

            # diff_entropy
            for i in range(n_levels-1):
                pxy = glcm_xminusy(glcm, k=i, distance=d, angle=a)
                if pxy > 0: diff_entropies[d,a] += pxy * np.log2(pxy)
            diff_entropies[d,a] *= -1

            # energy
            energies[d,a] = np.sum(np.square(glcm[...,d,a]))

            # entropy
            entropies[d,a] = skimage.measure.shannon_entropy(glcm[...,d,a])

            for i in range(2*(n_levels)-1):
                # sum averages
                pxy = glcm_xplusy(glcm, k=i, distance=d, angle=a)
                sum_averages[d,a] += (i+2) * pxy

                # sum entropies
                if pxy > 0: sum_entropies[d,a] += pxy * np.log2(pxy)

            sum_entropies[d,a] *= -1

            for i in range(2*(n_levels) - 1):
                # sum variances
                pxy = glcm_xplusy(glcm, k=i-1, distance=d, angle=a)
                sum_variances[d,a] += ((i+2 - sum_entropies[d,a])**2) * pxy

        # Average all the angles
        tex_features[f'{pref}_mean'] = np.mean(means)
        tex_features[f'{pref}_var'] = np.mean(variances)
        tex_features[f'{pref}_ac'] = np.mean(autocorrelations)
        tex_features[f'{pref}_cProminence'] = np.mean(cluster_prominences)
        tex_features[f'{pref}_cShade'] = np.mean(cluster_shades)
        tex_features[f'{pref}_cTendency'] = np.mean(cluster_tendencies)
        tex_features[f'{pref}_contrast'] = np.mean(greycoprops(glcm, 'contrast'))
        tex_features[f'{pref}_corr'] = np.mean(greycoprops(glcm, 'correlation'))
        tex_features[f'{pref}_diffentropy'] = np.mean(diff_entropies)
        tex_features[f'{pref}_dissimilarity'] = np.mean(greycoprops(glcm, 'dissimilarity'))
        tex_features[f'{pref}_energy'] = np.mean(energies)
        tex_features[f'{pref}_ent'] = np.mean(entropies)
        tex_features[f'{pref}_homogeneity1'] = np.mean(hgn1s)
        tex_features[f'{pref}_homogeneity2'] = np.mean(greycoprops(glcm, 'homogeneity'))
        tex_features[f'{pref}_idmn'] = np.mean(idmns)
        tex_features[f'{pref}_idn'] = np.mean(idns)
        tex_features[f'{pref}_iv'] = np.mean(inverse_variances)
        tex_features[f'{pref}_maxProb'] = np.mean(glcm.max(axis=(0,1)))
        tex_features[f'{pref}_sumaverage'] = np.mean(sum_averages)
        tex_features[f'{pref}_sumentropy'] = np.mean(sum_entropies)
        tex_features[f'{pref}_sumvariance'] = np.mean(sum_variances)

        # Information measures of correlation TODO
        #tex_features[f'{pref}_icm1'] = None
        #tex_features[f'{pref}_icm2'] = None

    return tex_features

# Cell

def process_image_features(fn:str, mask_plot:bool=True, radius:int=31):
    "Process rasters to tabular format. Todo Textural features parasm"
    image_features = image_metrics(fn, mask_plot=mask_plot, radius=radius)
    texture_features = textural_features(fn)
    features = {**image_features, **texture_features}
    return features