# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_tabular.preprocessing.ipynb (unless otherwise specified).

__all__ = ['get_lidar_feature', 'get_image_procs', 'EnvecoPreprocessor']

# Cell
from fastai.tabular.all import *
from fastai.data.all import *
from fastai.vision.data import get_grid
from ..data.las import *
from ..data.image import *
import matplotlib.patches as mpl_patches
from typing import Tuple
from fastai.metrics import *

# Cell

def get_lidar_feature(row, path, feature_func, min_h:float=1.5, mask_plot=True):
    "Function for LiDAR opening and processing steps"
    las_data = las_to_df(f'{path}/{row.sampleplotid}.las')
    if mask_plot == True: las_data = mask_plot_from_lidar(las_data, row.x, row.y)
    features = feature_func(las_data, min_h)
    return features

# Cell

def get_image_procs(row, path, radius=31, mask_plot=True):
    "Function for tif opening and processing steps"
    image_data = open_geotiff(f'{path}/{row.sampleplotid}.tif')
    if mask_plot == True: image_data = mask_plot_from_image(image_data, radius=radius)
    metrics = calc_image_metrics(image_data)
    return metrics

# Cell

class EnvecoPreprocessor():

    def __init__(self, train_path, valid_path, test_path, **kwargs):
        self.train_df = pd.read_csv(train_path)
        self.train_df = self.train_df.rename(columns = lambda x: re.sub('[\.]+', '_', x))
        self.valid_df = pd.read_csv(valid_path)
        self.valid_df = self.valid_df.rename(columns = lambda x: re.sub('[\.]+', '_', x))
        self.test_df = pd.read_csv(test_path)
        self.test_df = self.test_df.rename(columns = lambda x: re.sub('[\.]+', '_', x))
        self.train_df['is_valid'] = 0
        self.valid_df['is_valid'] = 1
        self.train_val_df = pd.concat((self.train_df, self.valid_df))


    def preprocess_lidar(self, target_col, path, min_h:float=1.5, mask_plot:bool=True, height_features:bool=True,
                         point_features:bool=True, intensity_features:bool=True, height_quantiles:bool=True,
                         point_proportions:bool=True, canopy_densities:bool=True, normalize:bool=True,
                         log_y:bool=False) -> Tuple[TabularPandas, TabularPandas]:
        "Preprocess data and return (train_val, test) -tuple. Optionally log-transform target column with np.log1p"
        trainval = self.train_val_df.copy()
        test = self.test_df.copy()
        feature_cols = []
        if height_features:
            print('Adding height based features')
            trainval[height_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_height_features,
                                                                                 min_h, mask_plot),
                                                   axis=1, result_type='expand')
            test[height_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_height_features,
                                                                         min_h, mask_plot),
                                           axis=1, result_type='expand')
            feature_cols.extend(height_cols)

        if point_features:
            print('Adding point distribution based features')
            trainval[point_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_point_features,
                                                                                min_h, mask_plot),
                                                   axis=1, result_type='expand')
            test[point_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_point_features,
                                                                                 min_h, mask_plot),
                                           axis=1, result_type='expand')
            feature_cols.extend(point_cols)

        if intensity_features:
            print('Adding intensity based features')
            trainval[intensity_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_intensity_features,
                                                                                    min_h, mask_plot),
                                                   axis=1, result_type='expand')
            test[intensity_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_intensity_features,
                                                                            min_h, mask_plot),
                                              axis=1, result_type='expand')
            feature_cols.extend(intensity_cols)

        if height_quantiles:
            print('Adding height quantiles')
            trainval[quantile_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_height_quantiles,
                                                                                  min_h, mask_plot),
                                                   axis=1, result_type='expand')
            test[quantile_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_height_quantiles,
                                                                           min_h, mask_plot),
                                             axis=1, result_type='expand')
            feature_cols.extend(quantile_cols)

        if point_proportions:
            print('Adding point proportions')
            trainval[proportion_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_point_proportions,
                                                                                    min_h, mask_plot),
                                                       axis=1, result_type='expand')
            test[proportion_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_point_proportions,
                                                                                 min_h, mask_plot),
                                               axis=1, result_type='expand')
            feature_cols.extend(proportion_cols)

        if canopy_densities:
            print('Adding canopy densities')
            trainval[density_cols] = trainval.apply(lambda row: get_lidar_feature(row, path, calc_canopy_densities,
                                                                                    min_h, mask_plot),
                                                       axis=1, result_type='expand')
            test[density_cols] = test.apply(lambda row: get_lidar_feature(row, path, calc_canopy_densities,
                                                                                 min_h, mask_plot),
                                               axis=1, result_type='expand')
            feature_cols.extend(density_cols)

        if log_y:
            trainval[target_col] = np.log1p(trainval[target_col])
            test[target_col] = np.log1p(test[target_col])

        means = []
        stds = []
        #for c in feature_cols:
        #    means.append(trainval[trainval.is_valid==0][c].mean())
        #    stds.append(trainval[trainval.is_valid==0][c].std())
        #norm_stats = np.array((means,stds))
        procs = None
        if normalize:
            procs = [Normalize]#.from_stats(*norm_stats)]
        trainval_tb = TabularPandas(trainval, procs=procs,
                                    cont_names=feature_cols, y_names=target_col,
                                    splits=ColSplitter(col='is_valid')(trainval))
        test_tb = TabularPandas(test, procs=procs,
                                cont_names=feature_cols, y_names=target_col)
        return trainval_tb, test_tb

    def preprocess_image(self, target_col, path, radius:int=31, mask_plot=True) -> Tuple[TabularPandas, TabularPandas]:
        "Preprocess dataframes and return (train_val, test) -tuple"
        # TODO
        pass

    def preprocess_lidar_and_image(self, target_col, path, min_h:float=1.5, radius:int=31,
                                   mask_plot:bool=True) -> Tuple[TabularPandas, TabularPandas]:
        "Preprocess dataframes and return (train_val, test) -tuple"
        # TODO
        pass